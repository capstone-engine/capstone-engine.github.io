<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Capstone - Disssemble in iterartion style</title><link rel="stylesheet" href="css/style.css" type="text/css" media="all"><link rel="stylesheet" href="css/pygments.css" type="text/css" media="all"><link rel="alternate" href="feed/index.xml" type="application/atom+xml" title="Atom Feed"></head><body><div id="fb-root"></div> <script>!function(e,t,n){var c,o=e.getElementsByTagName(t)[0];e.getElementById(n)||(c=e.createElement(t),c.id=n,c.src="//connect.facebook.net/en_US/all.js#xfbml=1",o.parentNode.insertBefore(c,o))}(document,"script","facebook-jssdk")</script><script>!function(t,e,r){var n,s=t.getElementsByTagName(e)[0],i=/^http:/.test(t.location)?"http":"https";t.getElementById(r)||(n=t.createElement(e),n.id=r,n.src=i+"://platform.twitter.com/widgets.js",s.parentNode.insertBefore(n,s))}(document,"script","twitter-wjs")</script><script>!function(){var e=document.createElement("script");e.type="text/javascript",e.async=!0,e.src="https://apis.google.com/js/plusone.js";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><div class="page"> <header> <a href="index.html" id="cs_home">Capstone</a> <nav> <a href="index.html">Home</a> <a href="download.html">Download</a> <a href="documentation.html">Docs</a> <a href="showcase.html">Showcase</a> <a href="testimonial.html">Testimonials</a> <a href="donation.html">Donate</a> <a href="contact.html">Contact</a> </nav> </header> <section><h3 id="introduction-of-csdisasmiter-api">1. Introduction of cs_disasm_iter API.</h3><p>The API <em>cs_disasm</em> automatically allocates memory internally for disassembled instructions, which is expensive if we need to decode a lot of instructions.</p><p>From version 3.0, Capstone provides <strong>cs_disasm_iter</strong>, a new API that can improve the performance by up to 30% depending on cases. The principle is: rather than letting the core allocate memory, <em>user pre-allocates the memory required</em>, then pass it to the core, so Capstone can reuse the same memory to store the disassembled instructions. Elimination of many alloc/realloc calls is the reason behind the performance gained.</p><p>See below for a sample C code demonstrating this API.</p><div class="highlight"><pre><code class="language-c" data-lang="c"><span class="lineno"> 1</span> <span class="n">csh</span> <span class="n">handle</span><span class="p">;</span>
<span class="lineno"> 2</span>     <span class="n">cs_open</span><span class="p">(</span><span class="n">CS_ARCH_X86</span><span class="p">,</span> <span class="n">CS_MODE_32</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">handle</span><span class="p">);</span>
<span class="lineno"> 3</span>
<span class="lineno"> 4</span>     <span class="c1">// allocate memory cache for 1 instruction, to be used by cs_disasm_iter later.</span>
<span class="lineno"> 5</span>     <span class="n">cs_insn</span> <span class="o">*</span><span class="n">insn</span> <span class="o">=</span> <span class="n">cs_malloc</span><span class="p">(</span><span class="n">handle</span><span class="p">);</span>
<span class="lineno"> 6</span>
<span class="lineno"> 7</span>     <span class="kt">uint8_t</span> <span class="o">*</span><span class="n">code</span> <span class="o">=</span> <span class="s">"</span><span class="se">\x90\x91\x92</span><span class="s">"</span><span class="p">;</span>
<span class="lineno"> 8</span> 	<span class="kt">size_t</span> <span class="n">code_size</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>	<span class="c1">// size of @code buffer above</span>
<span class="lineno"> 9</span> 	<span class="kt">uint64_t</span> <span class="n">address</span> <span class="o">=</span> <span class="mh">0x1000</span><span class="p">;</span>	<span class="c1">// address of first instruction to be disassembled</span>
<span class="lineno">10</span>
<span class="lineno">11</span>     <span class="c1">// disassemble one instruction a time &amp; store the result into @insn variable above</span>
<span class="lineno">12</span>     <span class="k">while</span><span class="p">(</span><span class="n">cs_disasm_iter</span><span class="p">(</span><span class="n">handle</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">code</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">code_size</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">address</span><span class="p">,</span> <span class="n">insn</span><span class="p">))</span> <span class="p">{</span>
<span class="lineno">13</span>         <span class="c1">// analyze disassembled instruction in @insn variable ...</span>
<span class="lineno">14</span>         <span class="c1">// NOTE: @code, @code_size &amp; @address variables are all updated</span>
<span class="lineno">15</span>         <span class="c1">// to point to the next instruction after each iteration.</span>
<span class="lineno">16</span>     <span class="p">}</span>
<span class="lineno">17</span>
<span class="lineno">18</span>     <span class="c1">// release the cache memory when done</span>
<span class="lineno">19</span>     <span class="n">cs_free</span><span class="p">(</span><span class="n">insn</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span></code></pre></div><p><br/></p><ul><li><p>On <em>line 5</em>, we pre-allocate memory for one instruction and keep it in the variable <em>insn</em>. This is done thanks to <strong>cs_malloc</strong>, another new API introduced in Capstone 3.0.</p></li><li><p>One <em>line 12</em>, we disassemble one instruction a time in a loop with <em>cs_disasm_iter</em>, which takes 5 arguments: the Capstone handle, the pointer to the input binary code, the pointer to the size of this input, the pointer to the address of the first instruction &amp; the memory cache generated in <em>line 5</em>. On success, this API updates all these pointers to the next instruction, making it ready for the next iteration in the <em>while</em> loop.</p><p>The API <em>cs_disasm_iter</em> returns <em>true</em> when it successfully decodes one instruction, or <em>false</em> otherwise. Therefore, readers can see that the <em>while</em> loop will disassemble until it either hits an invalid instruction, or end of the input buffer. Inside the loop, we would do usual binary analysis on the resulted instruction.</p></li><li><p>On <em>line 19</em>, we release the cache memory allocated by <em>cs_malloc</em> with <em>cs_free</em>. Note that we have to tell <em>cs_free</em> to <em>free 1 instruction</em> because this is what <em>cs_malloc</em> did in <em>line 5</em> above: allocated memory for 1 instruction of the type <em>cs_insn</em>.</p></li></ul><hr/><h3 id="notes">2. Notes.</h3><p>Internally, <em>cs_disasm_iter</em> behaves exactly like <em>cs_disasm</em> if we call <em>cs_disasm</em> with argument <em>count = 1</em>. However, <em>cs_disasm_iter</em> is faster because it reuses (and also overwrites) the same memory to store disassembled instruction, avoiding all the malloc/realloc in the loop above. So if we just need to do some quick iteration through all the instructions, <em>cs_disasm_iter</em> should be considered.</p><p>On the other hand, <em>cs_disasm</em> is more approriate when we want to disassemble all the instructions (using <em>count = 0</em>), or when we want to save all the disassembled instructions - without overwriting them in the loop - for future reference.</p><p>See a full sample of <em>cs_disasm_iter</em> &amp; <em>cs_malloc</em> in <a href="https://github.com/aquynh/capstone/blob/next/tests/test_iter.c">https://github.com/aquynh/capstone/blob/next/tests/test_iter.c</a></p></section> <footer> </footer></div></body></html>